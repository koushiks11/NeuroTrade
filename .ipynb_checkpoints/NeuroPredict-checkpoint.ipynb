{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a0610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Collection\n",
    "import pandas_datareader as pdr\n",
    "key=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb941ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def json_to_csv(input_file, output_file):\n",
    "    with open(input_file, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Extract keys (dates)\n",
    "    dates = sorted(data.keys())\n",
    "    keys = data[dates[0]].keys()\n",
    "\n",
    "    with open(output_file, 'w', newline='') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=['Date'] + list(keys))\n",
    "        writer.writeheader()\n",
    "\n",
    "        for date in dates:\n",
    "            row = {'Date': date}\n",
    "            row.update(data[date])\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Example usage:\n",
    "json_to_csv('sample.json', 'output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80157e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9131103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d155f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividend amount</th>\n",
       "      <th>split coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>354.4090</td>\n",
       "      <td>371.0715</td>\n",
       "      <td>354.4090</td>\n",
       "      <td>370.1173</td>\n",
       "      <td>79.2399</td>\n",
       "      <td>11842921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>364.5972</td>\n",
       "      <td>371.3782</td>\n",
       "      <td>360.8491</td>\n",
       "      <td>361.7351</td>\n",
       "      <td>77.4453</td>\n",
       "      <td>10059943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>358.1230</td>\n",
       "      <td>363.9158</td>\n",
       "      <td>351.8194</td>\n",
       "      <td>361.1217</td>\n",
       "      <td>77.3140</td>\n",
       "      <td>16954266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>357.7824</td>\n",
       "      <td>365.6195</td>\n",
       "      <td>356.1468</td>\n",
       "      <td>358.4297</td>\n",
       "      <td>76.7377</td>\n",
       "      <td>13446517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-07</td>\n",
       "      <td>359.8269</td>\n",
       "      <td>373.1159</td>\n",
       "      <td>359.5202</td>\n",
       "      <td>368.5840</td>\n",
       "      <td>78.9116</td>\n",
       "      <td>16969845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      open      high       low     close  adjusted close  \\\n",
       "0  2005-01-03  354.4090  371.0715  354.4090  370.1173         79.2399   \n",
       "1  2005-01-04  364.5972  371.3782  360.8491  361.7351         77.4453   \n",
       "2  2005-01-05  358.1230  363.9158  351.8194  361.1217         77.3140   \n",
       "3  2005-01-06  357.7824  365.6195  356.1468  358.4297         76.7377   \n",
       "4  2005-01-07  359.8269  373.1159  359.5202  368.5840         78.9116   \n",
       "\n",
       "     volume  dividend amount  split coefficient  \n",
       "0  11842921              0.0                1.0  \n",
       "1  10059943              0.0                1.0  \n",
       "2  16954266              0.0                1.0  \n",
       "3  13446517              0.0                1.0  \n",
       "4  16969845              0.0                1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01be70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.reset_index()['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc61c856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d2335170d0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4194bc91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0133 - val_loss: 0.2935\n",
      "Epoch 2/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0075 - val_loss: 0.3018\n",
      "Epoch 3/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0071 - val_loss: 0.3483\n",
      "Epoch 4/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0068 - val_loss: 0.3116\n",
      "Epoch 5/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0065 - val_loss: 0.3336\n",
      "Epoch 6/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0066 - val_loss: 0.3162\n",
      "Epoch 7/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0063 - val_loss: 0.3316\n",
      "Epoch 8/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0064 - val_loss: 0.3589\n",
      "Epoch 9/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0057 - val_loss: 0.3206\n",
      "Epoch 10/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0062 - val_loss: 0.3563\n",
      "Epoch 11/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0062 - val_loss: 0.3304\n",
      "Epoch 12/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0062 - val_loss: 0.3506\n",
      "Epoch 13/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0063 - val_loss: 0.3193\n",
      "Epoch 14/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0060 - val_loss: 0.3511\n",
      "Epoch 15/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0058 - val_loss: 0.3222\n",
      "Epoch 16/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0058 - val_loss: 0.3260\n",
      "Epoch 17/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0052 - val_loss: 0.3391\n",
      "Epoch 18/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0044 - val_loss: 0.2891\n",
      "Epoch 19/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0048 - val_loss: 0.3325\n",
      "Epoch 20/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.3024\n",
      "Epoch 21/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0039 - val_loss: 0.3545\n",
      "Epoch 22/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0042 - val_loss: 0.3119\n",
      "Epoch 23/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0039 - val_loss: 0.3388\n",
      "Epoch 24/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0038 - val_loss: 0.3351\n",
      "Epoch 25/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0038 - val_loss: 0.3400\n",
      "Epoch 26/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0035 - val_loss: 0.2771\n",
      "Epoch 27/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0038 - val_loss: 0.3120\n",
      "Epoch 28/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0036 - val_loss: 0.3163\n",
      "Epoch 29/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0034 - val_loss: 0.3279\n",
      "Epoch 30/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0035 - val_loss: 0.2678\n",
      "Epoch 31/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0035 - val_loss: 0.3270\n",
      "Epoch 32/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0036 - val_loss: 0.3169\n",
      "Epoch 33/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0034 - val_loss: 0.2943\n",
      "Epoch 34/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0032 - val_loss: 0.2937\n",
      "Epoch 35/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0030 - val_loss: 0.3335\n",
      "Epoch 36/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0033 - val_loss: 0.3153\n",
      "Epoch 37/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0030 - val_loss: 0.3341\n",
      "Epoch 38/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0032 - val_loss: 0.3236\n",
      "Epoch 39/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - val_loss: 0.3141\n",
      "Epoch 40/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0028 - val_loss: 0.2784\n",
      "Epoch 41/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0036 - val_loss: 0.3259\n",
      "Epoch 42/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0030 - val_loss: 0.2930\n",
      "Epoch 43/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0030 - val_loss: 0.3130\n",
      "Epoch 44/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0027 - val_loss: 0.3247\n",
      "Epoch 45/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0030 - val_loss: 0.2991\n",
      "Epoch 46/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0031 - val_loss: 0.3123\n",
      "Epoch 47/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0027 - val_loss: 0.3066\n",
      "Epoch 48/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0029 - val_loss: 0.3096\n",
      "Epoch 49/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0025 - val_loss: 0.3057\n",
      "Epoch 50/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0026 - val_loss: 0.3102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d25e693490>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Data Preparation\n",
    "X = df.drop(['Date', 'adjusted close'], axis=1).values  # No need to change this line\n",
    "y = df['adjusted close'].values\n",
    "\n",
    "# Reshape X to have 1 feature per column\n",
    "X = X.reshape(-1, 7)  # Assuming there are 7 features in your dataset\n",
    "\n",
    "# Scale features and target\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# Sequence Generation\n",
    "sequence_length = 10  # adjust as needed\n",
    "\n",
    "X_sequences = []\n",
    "y_sequences = []\n",
    "\n",
    "for i in range(sequence_length, len(X_scaled)):\n",
    "    X_sequences.append(X_scaled[i-sequence_length:i, :])\n",
    "    y_sequences.append(y_scaled[i, 0])\n",
    "\n",
    "X_sequences = np.array(X_sequences)\n",
    "y_sequences = np.array(y_sequences)\n",
    "\n",
    "# Split data into train and test sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * len(X_sequences))\n",
    "\n",
    "X_train = X_sequences[:split_index]\n",
    "X_test = X_sequences[split_index:]\n",
    "y_train = y_sequences[:split_index]\n",
    "y_test = y_sequences[split_index:]\n",
    "\n",
    "# Model Training\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "409cf2ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save(\"trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "93e5ded5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1551\n",
      "Evaluation Loss: 0.31028494238853455\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"trained_model.h5\")\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Evaluation Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29409386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 7 features, but MinMaxScaler is expecting 1 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m model_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Filepath to the saved model\u001b[39;00m\n\u001b[0;32m     21\u001b[0m given_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2005-01-20\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 22\u001b[0m predicted_close \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_adjusted_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgiven_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Adjusted Close for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgiven_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_close\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[61], line 10\u001b[0m, in \u001b[0;36mpredict_adjusted_close\u001b[1;34m(model_file, df, scaler, date)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Prepare input data for prediction\u001b[39;00m\n\u001b[0;32m      9\u001b[0m input_data \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m date]\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madjusted close\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m---> 10\u001b[0m input_data_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m input_data_scaled \u001b[38;5;241m=\u001b[39m input_data_scaled\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, input_data_scaled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], input_data_scaled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Make prediction\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:534\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    530\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    532\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 534\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m X \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    543\u001b[0m X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 7 features, but MinMaxScaler is expecting 1 features as input."
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Define the predict_adjusted_close function\n",
    "def predict_adjusted_close(model_file, df, scaler, date):\n",
    "    # Load the saved model\n",
    "    model = load_model(model_file)\n",
    "    \n",
    "    # Prepare input data for prediction\n",
    "    input_data = df[df['Date'] == date].drop(['Date', 'adjusted close'], axis=1).values\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "    input_data_scaled = input_data_scaled.reshape(1, input_data_scaled.shape[0], input_data_scaled.shape[1])\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction_scaled = model.predict(input_data_scaled)\n",
    "    prediction = scaler.inverse_transform(prediction_scaled)\n",
    "    \n",
    "    return prediction[0][0]\n",
    "\n",
    "# Example usage\n",
    "model_file = \"trained_model.h5\"  # Filepath to the saved model\n",
    "given_date = '2005-01-20'\n",
    "predicted_close = predict_adjusted_close(model_file, df, scaler, given_date)\n",
    "print(f'Predicted Adjusted Close for {given_date}: {predicted_close}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "566175d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 7 features, but MinMaxScaler is expecting 1 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m      2\u001b[0m given_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022-12-30\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m predicted_close \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_adjusted_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgiven_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Adjusted Close for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgiven_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_close\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[49], line 7\u001b[0m, in \u001b[0;36mpredict_adjusted_close\u001b[1;34m(model, df, date, scaler)\u001b[0m\n\u001b[0;32m      4\u001b[0m input_data \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m date]\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madjusted close\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Reshape input data for LSTM\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m input_data_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m input_data_scaled \u001b[38;5;241m=\u001b[39m input_data_scaled\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, input_data_scaled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], input_data_scaled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Make prediction\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:534\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    530\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    532\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 534\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m X \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    543\u001b[0m X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 7 features, but MinMaxScaler is expecting 1 features as input."
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "given_date = '2022-12-30'\n",
    "predicted_close = predict_adjusted_close(model, df, given_date, scaler)\n",
    "print(f'Predicted Adjusted Close for {given_date}: {predicted_close}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a3e8c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.00396369 0.00889342 0.00591213 ... 0.0147112  0.         0.        ]\n",
      "  [0.00790098 0.00901062 0.00846911 ... 0.01248843 0.         0.        ]\n",
      "  [0.00539899 0.00615898 0.00488395 ... 0.02108333 0.         0.        ]\n",
      "  ...\n",
      "  [0.00421392 0.00535164 0.00454575 ... 0.01798771 0.         0.        ]\n",
      "  [0.00421392 0.00394535 0.00562805 ... 0.01687553 0.         0.        ]\n",
      "  [0.00447725 0.00329434 0.00349046 ... 0.01645398 0.         0.        ]]\n",
      "\n",
      " [[0.00790098 0.00901062 0.00846911 ... 0.01248843 0.         0.        ]\n",
      "  [0.00539899 0.00615898 0.00488395 ... 0.02108333 0.         0.        ]\n",
      "  [0.00526736 0.00681002 0.0066021  ... 0.01671035 0.         0.        ]\n",
      "  ...\n",
      "  [0.00421392 0.00394535 0.00562805 ... 0.01687553 0.         0.        ]\n",
      "  [0.00447725 0.00329434 0.00349046 ... 0.01645398 0.         0.        ]\n",
      "  [0.00237033 0.00199226 0.001867   ... 0.02067613 0.         0.        ]]\n",
      "\n",
      " [[0.00539899 0.00615898 0.00488395 ... 0.02108333 0.         0.        ]\n",
      "  [0.00526736 0.00681002 0.0066021  ... 0.01671035 0.         0.        ]\n",
      "  [0.00605747 0.00967465 0.00794148 ... 0.02110275 0.         0.        ]\n",
      "  ...\n",
      "  [0.00447725 0.00329434 0.00349046 ... 0.01645398 0.         0.        ]\n",
      "  [0.00237033 0.00199226 0.001867   ... 0.02067613 0.         0.        ]\n",
      "  [0.00263374 0.00309903 0.00298983 ... 0.03002211 0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.31611341 0.31226508 0.31803266 ... 0.00081799 0.         0.        ]\n",
      "  [0.31125164 0.30963497 0.32043964 ... 0.00050349 0.         0.        ]\n",
      "  [0.31371777 0.31191673 0.31944426 ... 0.00062474 0.         0.        ]\n",
      "  ...\n",
      "  [0.34257121 0.33860119 0.34174037 ... 0.00105105 0.         0.        ]\n",
      "  [0.33767423 0.33285323 0.33862757 ... 0.00070992 0.         0.        ]\n",
      "  [0.33105095 0.33208682 0.34081737 ... 0.00065565 0.         0.        ]]\n",
      "\n",
      " [[0.31125164 0.30963497 0.32043964 ... 0.00050349 0.         0.        ]\n",
      "  [0.31371777 0.31191673 0.31944426 ... 0.00062474 0.         0.        ]\n",
      "  [0.32988837 0.33267906 0.33667306 ... 0.00263101 0.         0.        ]\n",
      "  ...\n",
      "  [0.33767423 0.33285323 0.33862757 ... 0.00070992 0.         0.        ]\n",
      "  [0.33105095 0.33208682 0.34081737 ... 0.00065565 0.         0.        ]\n",
      "  [0.33283008 0.33151205 0.33736078 ... 0.00046305 0.         0.        ]]\n",
      "\n",
      " [[0.31371777 0.31191673 0.31944426 ... 0.00062474 0.         0.        ]\n",
      "  [0.32988837 0.33267906 0.33667306 ... 0.00263101 0.         0.        ]\n",
      "  [0.33531379 0.34304281 0.3463371  ... 0.00240343 0.         0.        ]\n",
      "  ...\n",
      "  [0.33105095 0.33208682 0.34081737 ... 0.00065565 0.         0.        ]\n",
      "  [0.33283008 0.33151205 0.33736078 ... 0.00046305 0.         0.        ]\n",
      "  [0.33076911 0.33405508 0.34152319 ... 0.000588   0.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "549a864f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividend amount</th>\n",
       "      <th>split coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>354.4090</td>\n",
       "      <td>371.0715</td>\n",
       "      <td>354.4090</td>\n",
       "      <td>370.1173</td>\n",
       "      <td>79.2399</td>\n",
       "      <td>11842921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>364.5972</td>\n",
       "      <td>371.3782</td>\n",
       "      <td>360.8491</td>\n",
       "      <td>361.7351</td>\n",
       "      <td>77.4453</td>\n",
       "      <td>10059943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>358.1230</td>\n",
       "      <td>363.9158</td>\n",
       "      <td>351.8194</td>\n",
       "      <td>361.1217</td>\n",
       "      <td>77.3140</td>\n",
       "      <td>16954266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>357.7824</td>\n",
       "      <td>365.6195</td>\n",
       "      <td>356.1468</td>\n",
       "      <td>358.4297</td>\n",
       "      <td>76.7377</td>\n",
       "      <td>13446517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-07</td>\n",
       "      <td>359.8269</td>\n",
       "      <td>373.1159</td>\n",
       "      <td>359.5202</td>\n",
       "      <td>368.5840</td>\n",
       "      <td>78.9116</td>\n",
       "      <td>16969845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      open      high       low     close  adjusted close  \\\n",
       "0 2005-01-03  354.4090  371.0715  354.4090  370.1173         79.2399   \n",
       "1 2005-01-04  364.5972  371.3782  360.8491  361.7351         77.4453   \n",
       "2 2005-01-05  358.1230  363.9158  351.8194  361.1217         77.3140   \n",
       "3 2005-01-06  357.7824  365.6195  356.1468  358.4297         76.7377   \n",
       "4 2005-01-07  359.8269  373.1159  359.5202  368.5840         78.9116   \n",
       "\n",
       "     volume  dividend amount  split coefficient  \n",
       "0  11842921              0.0                1.0  \n",
       "1  10059943              0.0                1.0  \n",
       "2  16954266              0.0                1.0  \n",
       "3  13446517              0.0                1.0  \n",
       "4  16969845              0.0                1.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3764056f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - loss: 0.0135 - val_loss: 0.2998\n",
      "Epoch 2/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0073 - val_loss: 0.2939\n",
      "Epoch 3/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0072 - val_loss: 0.2961\n",
      "Epoch 4/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0066 - val_loss: 0.2823\n",
      "Epoch 5/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0065 - val_loss: 0.3231\n",
      "Epoch 6/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0065 - val_loss: 0.3504\n",
      "Epoch 7/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0063 - val_loss: 0.3393\n",
      "Epoch 8/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0057 - val_loss: 0.3199\n",
      "Epoch 9/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0062 - val_loss: 0.3135\n",
      "Epoch 10/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0060 - val_loss: 0.3091\n",
      "Epoch 11/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0056 - val_loss: 0.3332\n",
      "Epoch 12/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0062 - val_loss: 0.3432\n",
      "Epoch 13/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0061 - val_loss: 0.3428\n",
      "Epoch 14/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0055 - val_loss: 0.3345\n",
      "Epoch 15/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0056 - val_loss: 0.3155\n",
      "Epoch 16/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0050 - val_loss: 0.3511\n",
      "Epoch 17/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0053 - val_loss: 0.3312\n",
      "Epoch 18/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0052 - val_loss: 0.3175\n",
      "Epoch 19/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0043 - val_loss: 0.3340\n",
      "Epoch 20/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0043 - val_loss: 0.3278\n",
      "Epoch 21/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.3027\n",
      "Epoch 22/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0040 - val_loss: 0.3209\n",
      "Epoch 23/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0037 - val_loss: 0.2987\n",
      "Epoch 24/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0038 - val_loss: 0.3103\n",
      "Epoch 25/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0035 - val_loss: 0.3312\n",
      "Epoch 26/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0039 - val_loss: 0.3357\n",
      "Epoch 27/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0036 - val_loss: 0.3147\n",
      "Epoch 28/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0040 - val_loss: 0.2619\n",
      "Epoch 29/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0039 - val_loss: 0.2948\n",
      "Epoch 30/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0033 - val_loss: 0.3013\n",
      "Epoch 31/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0032 - val_loss: 0.3011\n",
      "Epoch 32/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0037 - val_loss: 0.3210\n",
      "Epoch 33/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0032 - val_loss: 0.2774\n",
      "Epoch 34/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0038 - val_loss: 0.3047\n",
      "Epoch 35/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0029 - val_loss: 0.3091\n",
      "Epoch 36/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0029 - val_loss: 0.2731\n",
      "Epoch 37/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0034 - val_loss: 0.2893\n",
      "Epoch 38/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0030 - val_loss: 0.3122\n",
      "Epoch 39/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0029 - val_loss: 0.2776\n",
      "Epoch 40/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0031 - val_loss: 0.3252\n",
      "Epoch 41/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0030 - val_loss: 0.3009\n",
      "Epoch 42/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0027 - val_loss: 0.3275\n",
      "Epoch 43/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0029 - val_loss: 0.3035\n",
      "Epoch 44/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0027 - val_loss: 0.3399\n",
      "Epoch 45/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0034 - val_loss: 0.3226\n",
      "Epoch 46/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0026 - val_loss: 0.3067\n",
      "Epoch 47/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0028 - val_loss: 0.3045\n",
      "Epoch 48/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0026 - val_loss: 0.3035\n",
      "Epoch 49/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0026 - val_loss: 0.2737\n",
      "Epoch 50/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0029 - val_loss: 0.3349\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893ms/step\n",
      "Predicted adjusted close for 2022-12-23: 489.29483\n",
      "Final Training Loss: 0.0026522648986428976\n",
      "Final Validation Loss: 0.33493784070014954\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "X = df.drop(['Date', 'adjusted close'], axis=1).values\n",
    "y = df['adjusted close'].values\n",
    "\n",
    "# Reshape X to have 1 feature per column\n",
    "X = X.reshape(-1, 7)\n",
    "\n",
    "# Scale features and target\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Sequence Generation\n",
    "sequence_length = 10\n",
    "X_sequences = []\n",
    "y_sequences = []\n",
    "\n",
    "for i in range(sequence_length, len(X_scaled)):\n",
    "    X_sequences.append(X_scaled[i-sequence_length:i, :])\n",
    "    y_sequences.append(y_scaled[i, 0])\n",
    "\n",
    "X_sequences = np.array(X_sequences)\n",
    "y_sequences = np.array(y_sequences)\n",
    "\n",
    "# Split data into train and test sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * len(X_sequences))\n",
    "\n",
    "X_train = X_sequences[:split_index]\n",
    "X_test = X_sequences[split_index:]\n",
    "y_train = y_sequences[:split_index]\n",
    "y_test = y_sequences[split_index:]\n",
    "\n",
    "# Model Training\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64, verbose=1)\n",
    "\n",
    "# Prediction for 2022-12-23\n",
    "last_sequence = X_scaled[-sequence_length:]\n",
    "last_sequence = last_sequence.reshape((1, sequence_length, X_train.shape[2]))\n",
    "predicted_scaled = model.predict(last_sequence)\n",
    "\n",
    "# Inverse scaling for predicted value\n",
    "predicted = scaler.inverse_transform(predicted_scaled)\n",
    "\n",
    "print(\"Predicted adjusted close for 2022-12-23:\", predicted[0][0])\n",
    "\n",
    "# Evaluation Loss\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "print(\"Final Training Loss:\", train_loss[-1])\n",
    "print(\"Final Validation Loss:\", val_loss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a16f39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Predicted adjusted close for 2022-12-23: 2101.6638\n",
      "Final Training Loss: 0.003265145467594266\n",
      "Final Validation Loss: 0.3212943375110626\n"
     ]
    }
   ],
   "source": [
    "# Prediction for 2022-12-23\n",
    "last_sequence = X_scaled[-sequence_length:]\n",
    "last_sequence = last_sequence.reshape((1, sequence_length, X_train.shape[2]))\n",
    "predicted_scaled = model.predict(last_sequence)\n",
    "\n",
    "# Inverse scaling for predicted value\n",
    "predicted = scale*scaler.inverse_transform(predicted_scaled)\n",
    "\n",
    "print(\"Predicted adjusted close for 2022-12-23:\", predicted[0][0])\n",
    "\n",
    "# Evaluation Loss\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "print(\"Final Training Loss:\", train_loss[-1])\n",
    "print(\"Final Validation Loss:\", val_loss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce923ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2c57dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Predicted adjusted close for 2022-12-23: 2101.663818359375\n",
      "Predicted adjusted close for 2022-12-24: 1876.0645751953125\n",
      "Predicted adjusted close for 2022-12-25: 1710.2967529296875\n",
      "Predicted adjusted close for 2022-12-26: 1583.054931640625\n",
      "Predicted adjusted close for 2022-12-27: 1492.78173828125\n",
      "Predicted adjusted close for 2022-12-28: 1439.8106689453125\n",
      "Predicted adjusted close for 2022-12-29: 1426.4786376953125\n",
      "Final Training Loss: 0.003265145467594266\n",
      "Final Validation Loss: 0.3212943375110626\n"
     ]
    }
   ],
   "source": [
    "# Prediction for 2022-12-23\n",
    "last_sequence = X_scaled[-sequence_length:]\n",
    "last_sequence = last_sequence.reshape((1, sequence_length, X_train.shape[2]))\n",
    "predicted_values_scaled = []\n",
    "\n",
    "# Predict for the next 7 days\n",
    "for i in range(7):\n",
    "    predicted_scaled = model.predict(last_sequence)\n",
    "    predicted_values_scaled.append(predicted_scaled[0][0])\n",
    "    last_sequence = np.roll(last_sequence, -1, axis=1)\n",
    "    last_sequence[0][-1] = predicted_scaled[0][0]\n",
    "\n",
    "# Inverse scaling for predicted values\n",
    "predicted_values = scale*scaler.inverse_transform(np.array(predicted_values_scaled).reshape(-1, 1))\n",
    "\n",
    "# Print predicted adjusted close values for each day\n",
    "for i in range(len(predicted_values)):\n",
    "    print(f\"Predicted adjusted close for 2022-12-{23+i}: {predicted_values[i][0]}\")\n",
    "\n",
    "# Evaluation Loss\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "print(\"Final Training Loss:\", train_loss[-1])\n",
    "print(\"Final Validation Loss:\", val_loss[-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
